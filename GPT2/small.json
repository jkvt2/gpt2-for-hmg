{
    "n_head": 8,
    "embed_dropout": 0.2,
    "lr": 0.0025,
    "warmup_steps": 2000,
    "beta1": 0.9,
    "beta2": 0.98,
    "epsilon": 1e-9,
    "opt_name": "adam",
    "weight_decay": 0.01,
    "train_batch_size": 8,
    "attn_dropout": 0.5,
    "train_steps": 20000,
    "train_noise": 0.2,
    "eval_steps": 10,
    "max_steps": 20000,
    "res_dropout": 0.5,
    "predict_batch_size": 1,
    "eval_batch_size": 10,
    "n_embd": 512,
    "input": "numbers",
    "model": "GPT2",
    "model_path": "checkpoints",
    "n_ctx": 30,
    "n_pred": 90,
    "predict_path": "logs",
    "n_layer": 6,
    "scale_by_depth": true,
    "scale_by_in": true,
    "multibin_nbins": 21,
    "multibin_overlap": 0.25,
    "multibin_min": -2,
    "multibin_max": 2
}
